{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmarieta/FaceRecognition/blob/main/Face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before starting, upload data.h5, data_submission.h5, IdLookupTable.csv and model.h5 files. After training your model, you can download it. After saving the output file, you can also download it."
      ],
      "metadata": {
        "id": "lBQAn62asEWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries\n"
      ],
      "metadata": {
        "id": "HCjTVDjLk_28"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsKs4kwPiiKV",
        "outputId": "a3047f61-59c4-4c5d-b65c-6384b9f2d616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyreadr in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyreadr) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadr) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadr) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyreadr) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "import pandas as pd\n",
        "import h5py\n",
        "#from sklearn import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install pyreadr\n",
        "import pyreadr\n",
        "from keras.optimizers import Adam\n",
        "from timeit import default_timer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from collections import OrderedDict\n",
        "from tensorflow.keras.models import clone_model, load_model\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization"
      ],
      "metadata": {
        "id": "dCq6AyUthC9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "pretraining = False"
      ],
      "metadata": {
        "id": "nzTL3YCHhF8q"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "9V6G9irLLxFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_filename = '/content/data.h5'\n",
        "submission_filename = '/content/data_submission.h5'\n",
        "\n",
        "## Get the indices of rows containing NaN values. Note that train and test splits are random with a given seed.\n",
        "# nan_indices_train = x_train.index[x_train.isnull().any(axis=1)].tolist() + y_train.index[y_train.isnull().any(axis=1)].tolist()\n",
        "# nan_indices_test = x_test.index[x_test.isnull().any(axis=1)].tolist() + y_test.index[y_test.isnull().any(axis=1)].tolist()\n",
        "\n",
        "## Drop rows containing NaN values\n",
        "# x_train = x_train.drop(x_train.index[nan_indices_train])\n",
        "# y_train = y_train.drop(y_train.index[nan_indices_train])\n",
        "# x_test = x_test.drop(x_test.index[nan_indices_test])\n",
        "# y_test = y_test.drop(y_test.index[nan_indices_test])\n",
        "\n"
      ],
      "metadata": {
        "id": "8sOJXEePLwc9"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(test=False, cols=None, fname=data_filename):\n",
        "    \"\"\"Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
        "    Pass a list of *cols* if you're only interested in a subset of the\n",
        "    target columns.\n",
        "    \"\"\"\n",
        "\n",
        "    with h5py.File(fname, 'r') as hdf_file:\n",
        "      if (fname == data_filename and test == False):\n",
        "        # Read DataFrames\n",
        "        X = pd.DataFrame(hdf_file['im_train'][:])\n",
        "        y = pd.DataFrame(hdf_file['d_train'][:])\n",
        "        y.columns = hdf_file['d_train'].attrs['column_names']\n",
        "      elif (fname == data_filename and test == True):\n",
        "        # Read DataFrames\n",
        "        X = pd.DataFrame(hdf_file['im_test'][:])\n",
        "        y = pd.DataFrame(hdf_file['d_test'][:])\n",
        "        y.columns = hdf_file['d_test'].attrs['column_names']\n",
        "      else:\n",
        "        # Read NumPy arrays\n",
        "        X = pd.DataFrame(np.array(hdf_file['submission_image'][:]))\n",
        "\n",
        "    if (cols and fname == data_filename):  # get a subset of columns\n",
        "        y = y[list(cols)]\n",
        "\n",
        "    X = np.vstack(X.values) / 255.  # scale pixel values to [0, 1]\n",
        "    X = X.astype(np.float32)\n",
        "\n",
        "    if fname == data_filename:  # only FTRAIN has any target columns\n",
        "        y = y.values\n",
        "        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
        "        y = y.astype(np.float32)\n",
        "    else:\n",
        "        y = None\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "PesN-UE7T-5V"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load2d(test=False, cols=None, fname=data_filename):\n",
        "    X, y = load(test=test,cols=cols,fname=fname)\n",
        "    X = X.reshape(-1, 96, 96, 1)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "NkqSAShVTwA0"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if pretraining == True:\n",
        "  x_train, y_train = load2d(test = False, fname = data_filename)\n",
        "else:\n",
        "  x_train, y_train = load(test = False, fname = data_filename)\n",
        "x_test, y_test = load2d(test = True, fname = data_filename)\n",
        "\n",
        "# Find rows with NaN values\n",
        "nan_rows = np.isnan(y_test).any(axis=1)\n",
        "\n",
        "# Use boolean indexing to drop rows with NaN values\n",
        "x_test = x_test[~nan_rows]\n",
        "y_test = y_test[~nan_rows]"
      ],
      "metadata": {
        "id": "So4pMJWKX1DU"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model selection"
      ],
      "metadata": {
        "id": "R1tsO8Kk6Jh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = 'Convolutions' # options: {'Single hidden layer','Convolutions'}\n",
        "df = pd.DataFrame({model_type}, columns=['Model type'])\n",
        "\n",
        "# Start recording time\n",
        "start = default_timer()"
      ],
      "metadata": {
        "id": "_BVmFiBg6LYp"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic momentum and learning rate"
      ],
      "metadata": {
        "id": "9xYT_lLnhSoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MomentumScheduler(Callback):\n",
        "    def __init__(self, schedule, decay_rate):\n",
        "        super(MomentumScheduler, self).__init__()\n",
        "        self.initial_schedule = schedule\n",
        "        self.decay_rate = decay_rate\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, 'beta_1'):\n",
        "            raise ValueError(\"Optimizer must have a 'beta_1' attribute.\")\n",
        "        momentum = self.initial_schedule + (self.decay_rate*epoch) / epochs\n",
        "        self.model.optimizer.beta_1 = momentum\n",
        "\n",
        "\n",
        "class LinearDecayLR(Callback):\n",
        "    def __init__(self, initial_lr, decay_rate):\n",
        "        super(LinearDecayLR, self).__init__()\n",
        "        self.initial_lr = initial_lr\n",
        "        self.decay_rate = decay_rate\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        new_lr = self.initial_lr - (self.decay_rate * epoch) / epochs\n",
        "        self.model.optimizer.lr = new_lr\n",
        "\n",
        "# Initialize for learning rate and momentum\n",
        "initial_momentum = 0.9 # TODO optimize\n",
        "momentum_decay_rate = 0.999 - initial_momentum\n",
        "\n",
        "initial_lr = 0.001 # TODO optimize\n",
        "final_lr = 0.00001\n",
        "lr_decay_rate = initial_lr - final_lr\n",
        "\n",
        "# Create callbacks\n",
        "momentum_callback = MomentumScheduler(initial_momentum, momentum_decay_rate)\n",
        "lr_callback = LinearDecayLR(initial_lr, lr_decay_rate)\n"
      ],
      "metadata": {
        "id": "Xo-F3T7rhXoF"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutions model"
      ],
      "metadata": {
        "id": "X8JbIEyf6AOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for specialist training\n",
        "SPECIALIST_SETTINGS = [\n",
        "    dict(\n",
        "        columns=(\n",
        "            'left_eye_center_x', 'left_eye_center_y',\n",
        "            'right_eye_center_x', 'right_eye_center_y',\n",
        "            ),\n",
        "        ),\n",
        "\n",
        "    dict(\n",
        "        columns=(\n",
        "            'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n",
        "            'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n",
        "            'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n",
        "            'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n",
        "            ),\n",
        "        ),\n",
        "\n",
        "    dict(\n",
        "        columns=(\n",
        "            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n",
        "            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n",
        "            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n",
        "            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
        "            ),\n",
        "        ),\n",
        "\n",
        "    dict(\n",
        "        columns=(\n",
        "            'nose_tip_x', 'nose_tip_y',\n",
        "            ),\n",
        "        ),\n",
        "\n",
        "    dict(\n",
        "        columns=(\n",
        "            'mouth_left_corner_x', 'mouth_left_corner_y',\n",
        "            'mouth_right_corner_x', 'mouth_right_corner_y',\n",
        "            'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
        "            ),\n",
        "        ),\n",
        "\n",
        "    dict(\n",
        "        columns=(\n",
        "            'mouth_center_bottom_lip_x',\n",
        "            'mouth_center_bottom_lip_y',\n",
        "            ),\n",
        "        ),\n",
        "    ]"
      ],
      "metadata": {
        "id": "D6GpxHMTIwMY"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if pretraining == True:\n",
        "  pixel_num = x_train.shape[1]\n",
        "\n",
        "  # Find rows with NaN values\n",
        "  nan_rows = np.isnan(y_train).any(axis=1)\n",
        "\n",
        "  # Use boolean indexing to drop rows with NaN values\n",
        "  x_train = x_train[~nan_rows]\n",
        "  y_train = y_train[~nan_rows]\n",
        "\n",
        "  # Assuming you have defined the input shape of your images\n",
        "  input_shape = (pixel_num, pixel_num, 1)\n",
        "\n",
        "  # Create the CNN model\n",
        "  net = keras.Sequential()\n",
        "\n",
        "  # Convolutional Layer 1\n",
        "  net.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "  #net.add(BatchNormalization())\n",
        "  net.add(MaxPooling2D((2, 2)))\n",
        "  net.add(Dropout(0.1))\n",
        "\n",
        "  # Convolutional Layer 2\n",
        "  net.add(Conv2D(64, (2, 2), activation='relu'))\n",
        "  #net.add(BatchNormalization())\n",
        "  net.add(MaxPooling2D((2, 2)))\n",
        "  net.add(Dropout(0.2))\n",
        "\n",
        "  # Convolutional Layer 3\n",
        "  net.add(Conv2D(128, (2, 2), activation='relu'))\n",
        "  net.add(Dropout(0.2))\n",
        "\n",
        "  # Convolutional Layer 4\n",
        "  net.add(Conv2D(256, (2, 2), activation='relu'))\n",
        "  net.add(BatchNormalization())\n",
        "  net.add(Dropout(0.2))\n",
        "\n",
        "  # Flatten the feature maps\n",
        "  net.add(Flatten())\n",
        "\n",
        "  # Fully Connected Layer 1\n",
        "  #net.add(Dense(200, activation='relu'))\n",
        "  #net.add(BatchNormalization())\n",
        "\n",
        "  # Fully Connected Layer 2\n",
        "  #net.add(Dense(200, activation='relu'))\n",
        "  #net.add(BatchNormalization())\n",
        "\n",
        "  # Output Layer\n",
        "  net.add(Dense(y_train.shape[1]))\n",
        "\n",
        "  ## Compile the model\n",
        "  # net.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "  # stop early\n",
        "  early_stopping = EarlyStopping(monitor='val_loss',patience=80, restore_best_weights=True)\n",
        "\n",
        "  # Create the Adam optimizer with the desired initial values\n",
        "  optimizer = Adam(learning_rate=initial_lr, beta_1 = initial_momentum)\n",
        "\n",
        "  # Compile the model and specify trainable variables\n",
        "  net.compile(optimizer=optimizer, loss='mse', metrics=['accuracy','mse'])\n",
        "\n",
        "  # Create a generator for training data\n",
        "  batch_size = 32\n",
        "\n",
        "  history = net.fit(x_train,\n",
        "                y_train,\n",
        "                batch_size = batch_size,\n",
        "                epochs = epochs,\n",
        "                callbacks = [early_stopping, lr_callback, momentum_callback],\n",
        "                validation_data=(x_test, y_test))\n",
        "\n",
        "  # Data augmentation\n",
        "  # Create an instance of ImageDataGenerator with desired augmentation settings\n",
        "  # data_generator = ImageDataGenerator(horizontal_flip = True, vertical_flip = True)\n"
      ],
      "metadata": {
        "id": "P-ttARWxVKli"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if pretraining == False:\n",
        "  # Convolutional neural net with three convolutional layers and two fully connected layers\n",
        "  keras.backend.clear_session()\n",
        "  pixel_num = np.sqrt(x_train.shape[1]).astype(int)\n",
        "  # Assuming you have defined the input shape of your images\n",
        "  input_shape = (pixel_num, pixel_num, 1)\n",
        "\n",
        "  # Load pre-trained model\n",
        "  base_model = load_model('/content/model.h5')\n",
        "  # Create the CNN model\n",
        "  net = keras.Sequential()\n",
        "\n",
        "  # Add the modified base model\n",
        "  for i in range(0,4):\n",
        "    net.add(base_model.layers[i])\n",
        "    #net.layers[0].trainable = False\n",
        "\n",
        "  #net.layers[0].trainable = False\n",
        "\n",
        "    # Convolutional Layer 1\n",
        "  net.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))\n",
        "  #net.add(MaxPooling2D((2, 2)))\n",
        "  #net.add(Dropout(0.1))\n",
        "\n",
        "  # Convolutional Layer 2\n",
        "  net.add(Conv2D(64, (2, 2), activation='relu'))\n",
        "  #net.add(MaxPooling2D((2, 2)))\n",
        "  #net.add(Dropout(0.1))\n",
        "\n",
        "  # Convolutional Layer 3\n",
        "  #net.add(Conv2D(128, (2, 2), activation='relu'))\n",
        "  #net.add(Dropout(0.1))\n",
        "  #net.add(BatchNormalization())\n",
        "\n",
        "\n",
        "  net.load_weights('/content/model.h5',by_name=True)\n",
        "\n",
        "  # Flatten the feature maps\n",
        "  net.add(Flatten())\n",
        "\n",
        "  # Fully Connected Layer 1\n",
        "  #net.add(Dense(200, activation='relu'))\n",
        "  #net.add(Dropout(0.2))\n",
        "\n",
        "  ## Compile the model\n",
        "  # net.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "  # stop early\n",
        "  early_stopping = EarlyStopping(monitor='loss',patience=50, restore_best_weights=True)\n",
        "\n",
        "  # Data augmentation\n",
        "  # Create an instance of ImageDataGenerator with desired augmentation settings\n",
        "  # data_generator = ImageDataGenerator(horizontal_flip = True, vertical_flip = True)\n",
        "\n",
        "  # Create a generator for training data\n",
        "  batch_size = 16\n",
        "  # train_generator = data_generator.flow(x_train, y_train, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "dx3WTFmO6F6V"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specialists = OrderedDict()\n",
        "val_loss_values = []\n",
        "training_loss_values = []\n",
        "predictions_list = []\n",
        "tmp = []\n",
        "tmp2 = []\n",
        "\n",
        "def fit_specialists(fname_pretrain=None):\n",
        "\n",
        "  for setting in SPECIALIST_SETTINGS:\n",
        "    cols = setting['columns']\n",
        "    x_train_cleaned, y_train_cleaned = load2d(cols=cols)\n",
        "    x_test_cleaned, y_test_cleaned = load2d(test = True, cols = cols, fname = data_filename)\n",
        "\n",
        "    # Find rows with NaN values\n",
        "    nan_rows = np.isnan(y_train_cleaned).any(axis=1)\n",
        "\n",
        "    # Use boolean indexing to drop rows with NaN values\n",
        "    x_train_cleaned = x_train_cleaned[~nan_rows]\n",
        "    y_train_cleaned = y_train_cleaned[~nan_rows]\n",
        "\n",
        "    # Find rows with NaN values\n",
        "    nan_rows = np.isnan(y_test_cleaned).any(axis=1)\n",
        "\n",
        "    # Use boolean indexing to drop rows with NaN values\n",
        "    x_test_cleaned = x_test_cleaned[~nan_rows]\n",
        "    y_test_cleaned = y_test_cleaned[~nan_rows]\n",
        "\n",
        "    model = clone_model(net)\n",
        "    # Output Layer\n",
        "    model.add(Dense(y_train_cleaned.shape[1]))\n",
        "\n",
        "    if 'kwargs' in setting:\n",
        "        # an option 'kwargs' in the settings list may be used to\n",
        "        # set any other parameter of the net:\n",
        "        vars(model).update(setting['kwargs'])\n",
        "\n",
        "    # Create the Adam optimizer with the desired initial values\n",
        "    optimizer = Adam(learning_rate=initial_lr, beta_1 = initial_momentum, clipvalue = 1)\n",
        "\n",
        "    # Compile the model and specify trainable variables\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "    print(\"Training model for columns {} for {} epochs\".format(\n",
        "        cols, epochs))\n",
        "\n",
        "    history = model.fit(x_train_cleaned,\n",
        "              y_train_cleaned,\n",
        "              batch_size = batch_size,\n",
        "              epochs = epochs,\n",
        "              callbacks = [early_stopping, lr_callback, momentum_callback],\n",
        "              validation_data=(x_test_cleaned, y_test_cleaned))\n",
        "    specialists[cols] = model\n",
        "\n",
        "    # Calculate and store the loss value for this specialist\n",
        "    val_loss = history.history['val_loss']\n",
        "    training_loss = history.history['loss']\n",
        "    val_loss_values.append((cols, val_loss))\n",
        "    training_loss_values.append((cols, training_loss))\n",
        "\n",
        "    # Make predictions using this specialist on the cleaned test data\n",
        "    predictions = model.predict(x_test)\n",
        "    predictions_list.append(predictions)"
      ],
      "metadata": {
        "id": "yvx4lOe6bHQc"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis"
      ],
      "metadata": {
        "id": "PQLVo5JVw-5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if pretraining == False:\n",
        "  fit_specialists()\n",
        "\n",
        "  # Combine predictions from all specialists\n",
        "  combined_predictions = np.hstack(predictions_list)\n",
        "else:\n",
        "  combined_predictions = net.predict(x_test)\n",
        "  # Save the model to a file\n",
        "  net.save('/content/model.h5')\n",
        "\n",
        "# Calculate the loss value for the combined predictions\n",
        "combined_loss = mean_squared_error(y_test, combined_predictions)\n",
        "\n",
        "# Duration\n",
        "duration = default_timer() - start\n",
        "print(duration)\n",
        "df['Duration'] = duration"
      ],
      "metadata": {
        "id": "GawC2VdexCmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9c9689-d0cc-4c59-9435-0f34c5428894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for columns ('left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y') for 500 epochs\n",
            "Epoch 1/500\n",
            "352/352 [==============================] - 7s 14ms/step - loss: 88.7994 - accuracy: 0.9913 - val_loss: 16.0678 - val_accuracy: 0.9950\n",
            "Epoch 2/500\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 16.6234 - accuracy: 0.9957 - val_loss: 25.8118 - val_accuracy: 0.9950\n",
            "Epoch 3/500\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 17.3244 - accuracy: 0.9957 - val_loss: 14.3415 - val_accuracy: 0.9950\n",
            "Epoch 4/500\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 18.8311 - accuracy: 0.9957 - val_loss: 25.1138 - val_accuracy: 0.9950\n",
            "Epoch 5/500\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 14.2137 - accuracy: 0.9957 - val_loss: 19.9285 - val_accuracy: 0.9950\n",
            "Epoch 6/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 12.0889 - accuracy: 0.9957 - val_loss: 10.9769 - val_accuracy: 0.9950\n",
            "Epoch 7/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 11.5297 - accuracy: 0.9957 - val_loss: 12.1283 - val_accuracy: 0.9950\n",
            "Epoch 8/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 11.6241 - accuracy: 0.9957 - val_loss: 10.9648 - val_accuracy: 0.9950\n",
            "Epoch 9/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 10.5593 - accuracy: 0.9957 - val_loss: 20.8049 - val_accuracy: 0.9950\n",
            "Epoch 10/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 10.9886 - accuracy: 0.9957 - val_loss: 8.9940 - val_accuracy: 0.9950\n",
            "Epoch 11/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 11.4961 - accuracy: 0.9957 - val_loss: 21.0074 - val_accuracy: 0.9950\n",
            "Epoch 12/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 11.1095 - accuracy: 0.9957 - val_loss: 11.3549 - val_accuracy: 0.9950\n",
            "Epoch 13/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 9.7443 - accuracy: 0.9957 - val_loss: 17.9116 - val_accuracy: 0.9950\n",
            "Epoch 14/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 10.3501 - accuracy: 0.9957 - val_loss: 8.0819 - val_accuracy: 0.9950\n",
            "Epoch 15/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 14.0535 - accuracy: 0.9957 - val_loss: 22.3727 - val_accuracy: 0.9950\n",
            "Epoch 16/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 11.6279 - accuracy: 0.9957 - val_loss: 8.7813 - val_accuracy: 0.9950\n",
            "Epoch 17/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 10.8611 - accuracy: 0.9957 - val_loss: 7.8531 - val_accuracy: 0.9950\n",
            "Epoch 18/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 10.9070 - accuracy: 0.9957 - val_loss: 11.2470 - val_accuracy: 0.9950\n",
            "Epoch 19/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 9.4918 - accuracy: 0.9957 - val_loss: 14.1501 - val_accuracy: 0.9950\n",
            "Epoch 20/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 8.8938 - accuracy: 0.9959 - val_loss: 11.1860 - val_accuracy: 0.9950\n",
            "Epoch 21/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 11.4279 - accuracy: 0.9957 - val_loss: 10.5995 - val_accuracy: 0.9950\n",
            "Epoch 22/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 12.0614 - accuracy: 0.9957 - val_loss: 7.4992 - val_accuracy: 0.9950\n",
            "Epoch 23/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 19.2532 - accuracy: 0.9959 - val_loss: 43.6335 - val_accuracy: 0.9950\n",
            "Epoch 24/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 10.7033 - accuracy: 0.9959 - val_loss: 9.1710 - val_accuracy: 0.9950\n",
            "Epoch 25/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 9.7809 - accuracy: 0.9959 - val_loss: 18.5357 - val_accuracy: 0.9950\n",
            "Epoch 26/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 9.5836 - accuracy: 0.9959 - val_loss: 14.1391 - val_accuracy: 0.9950\n",
            "Epoch 27/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 19.8986 - accuracy: 0.9961 - val_loss: 8.5694 - val_accuracy: 0.9950\n",
            "Epoch 28/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 14.7043 - accuracy: 0.9959 - val_loss: 16.1171 - val_accuracy: 0.9950\n",
            "Epoch 29/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 11.7939 - accuracy: 0.9961 - val_loss: 15.9342 - val_accuracy: 0.9950\n",
            "Epoch 30/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 10.4534 - accuracy: 0.9961 - val_loss: 8.1537 - val_accuracy: 0.9950\n",
            "Epoch 31/500\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 12.2056 - accuracy: 0.9957 - val_loss: 19.0835 - val_accuracy: 0.9950\n",
            "Epoch 32/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 11.7624 - accuracy: 0.9957 - val_loss: 9.6516 - val_accuracy: 0.9950\n",
            "Epoch 33/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 15.6877 - accuracy: 0.9959 - val_loss: 17.4585 - val_accuracy: 0.9950\n",
            "Epoch 34/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 12.1754 - accuracy: 0.9959 - val_loss: 15.0898 - val_accuracy: 0.9950\n",
            "Epoch 35/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 10.8453 - accuracy: 0.9961 - val_loss: 9.4753 - val_accuracy: 0.9950\n",
            "Epoch 36/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 10.7778 - accuracy: 0.9956 - val_loss: 13.5165 - val_accuracy: 0.9950\n",
            "Epoch 37/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 11.2752 - accuracy: 0.9964 - val_loss: 9.2311 - val_accuracy: 0.9950\n",
            "Epoch 38/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 11.1005 - accuracy: 0.9959 - val_loss: 12.3498 - val_accuracy: 0.9950\n",
            "Epoch 39/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 9.9493 - accuracy: 0.9961 - val_loss: 21.9838 - val_accuracy: 0.9950\n",
            "Epoch 40/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 9.1501 - accuracy: 0.9961 - val_loss: 8.0605 - val_accuracy: 0.9950\n",
            "Epoch 41/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 9.3534 - accuracy: 0.9959 - val_loss: 8.5400 - val_accuracy: 0.9950\n",
            "Epoch 42/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 11.7619 - accuracy: 0.9959 - val_loss: 8.8801 - val_accuracy: 0.9950\n",
            "Epoch 43/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 18.3182 - accuracy: 0.9957 - val_loss: 7.2587 - val_accuracy: 0.9950\n",
            "Epoch 44/500\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 10.2458 - accuracy: 0.9957 - val_loss: 9.6415 - val_accuracy: 0.9950\n",
            "Epoch 45/500\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 9.6761 - accuracy: 0.9957 - val_loss: 10.9215 - val_accuracy: 0.9950\n",
            "Epoch 46/500\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 9.1213 - accuracy: 0.9957 - val_loss: 8.6500 - val_accuracy: 0.9950\n",
            "Epoch 47/500\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 8.4910 - accuracy: 0.9963 - val_loss: 8.4701 - val_accuracy: 0.9950\n",
            "Epoch 48/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 7.2503 - accuracy: 0.9957 - val_loss: 9.7898 - val_accuracy: 0.9950\n",
            "Epoch 49/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 6.0670 - accuracy: 0.9956 - val_loss: 7.6797 - val_accuracy: 0.9950\n",
            "Epoch 50/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 5.8361 - accuracy: 0.9963 - val_loss: 10.1815 - val_accuracy: 0.9950\n",
            "Epoch 51/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 6.0064 - accuracy: 0.9963 - val_loss: 7.8851 - val_accuracy: 0.9957\n",
            "Epoch 52/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 6.6761 - accuracy: 0.9959 - val_loss: 8.3615 - val_accuracy: 0.9950\n",
            "Epoch 53/500\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 6.0307 - accuracy: 0.9957 - val_loss: 11.5255 - val_accuracy: 0.9950\n",
            "Epoch 54/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 5.9187 - accuracy: 0.9961 - val_loss: 7.4065 - val_accuracy: 0.9950\n",
            "Epoch 55/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 5.0329 - accuracy: 0.9961 - val_loss: 6.6089 - val_accuracy: 0.9950\n",
            "Epoch 56/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 4.4678 - accuracy: 0.9963 - val_loss: 7.4752 - val_accuracy: 0.9957\n",
            "Epoch 57/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 5.2426 - accuracy: 0.9961 - val_loss: 8.5593 - val_accuracy: 0.9957\n",
            "Epoch 58/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 5.3614 - accuracy: 0.9963 - val_loss: 9.8506 - val_accuracy: 0.9957\n",
            "Epoch 59/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 4.5740 - accuracy: 0.9961 - val_loss: 10.0661 - val_accuracy: 0.9950\n",
            "Epoch 60/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 4.6001 - accuracy: 0.9961 - val_loss: 7.1632 - val_accuracy: 0.9957\n",
            "Epoch 61/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 3.9902 - accuracy: 0.9961 - val_loss: 7.3236 - val_accuracy: 0.9957\n",
            "Epoch 62/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 3.7772 - accuracy: 0.9963 - val_loss: 6.9907 - val_accuracy: 0.9957\n",
            "Epoch 63/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 3.7135 - accuracy: 0.9964 - val_loss: 6.9198 - val_accuracy: 0.9957\n",
            "Epoch 64/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 3.5699 - accuracy: 0.9963 - val_loss: 7.5771 - val_accuracy: 0.9957\n",
            "Epoch 65/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 3.4072 - accuracy: 0.9963 - val_loss: 7.6570 - val_accuracy: 0.9957\n",
            "Epoch 66/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 3.2943 - accuracy: 0.9964 - val_loss: 7.6453 - val_accuracy: 0.9950\n",
            "Epoch 67/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 3.0202 - accuracy: 0.9970 - val_loss: 7.0571 - val_accuracy: 0.9957\n",
            "Epoch 68/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 2.8631 - accuracy: 0.9966 - val_loss: 6.7189 - val_accuracy: 0.9950\n",
            "Epoch 69/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 2.6426 - accuracy: 0.9968 - val_loss: 7.3625 - val_accuracy: 0.9950\n",
            "Epoch 70/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 2.7667 - accuracy: 0.9972 - val_loss: 7.8462 - val_accuracy: 0.9957\n",
            "Epoch 71/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 2.5810 - accuracy: 0.9975 - val_loss: 6.8229 - val_accuracy: 0.9957\n",
            "Epoch 72/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 2.7322 - accuracy: 0.9977 - val_loss: 7.5698 - val_accuracy: 0.9957\n",
            "Epoch 73/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 2.4207 - accuracy: 0.9975 - val_loss: 7.8008 - val_accuracy: 0.9957\n",
            "Epoch 74/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 2.2327 - accuracy: 0.9977 - val_loss: 7.1183 - val_accuracy: 0.9957\n",
            "Epoch 75/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 2.4208 - accuracy: 0.9973 - val_loss: 8.7712 - val_accuracy: 0.9957\n",
            "Epoch 76/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 2.3239 - accuracy: 0.9973 - val_loss: 7.0276 - val_accuracy: 0.9957\n",
            "Epoch 77/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 2.0456 - accuracy: 0.9973 - val_loss: 7.5782 - val_accuracy: 0.9957\n",
            "Epoch 78/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 1.8695 - accuracy: 0.9977 - val_loss: 7.3064 - val_accuracy: 0.9957\n",
            "Epoch 79/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.8181 - accuracy: 0.9975 - val_loss: 7.4429 - val_accuracy: 0.9957\n",
            "Epoch 80/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.8238 - accuracy: 0.9980 - val_loss: 7.5244 - val_accuracy: 0.9957\n",
            "Epoch 81/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.6935 - accuracy: 0.9975 - val_loss: 7.5827 - val_accuracy: 0.9950\n",
            "Epoch 82/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.7817 - accuracy: 0.9977 - val_loss: 7.7854 - val_accuracy: 0.9957\n",
            "Epoch 83/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 1.5841 - accuracy: 0.9975 - val_loss: 8.0475 - val_accuracy: 0.9950\n",
            "Epoch 84/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.4496 - accuracy: 0.9980 - val_loss: 8.0636 - val_accuracy: 0.9957\n",
            "Epoch 85/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 1.4564 - accuracy: 0.9973 - val_loss: 7.9807 - val_accuracy: 0.9957\n",
            "Epoch 86/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.5560 - accuracy: 0.9986 - val_loss: 7.8940 - val_accuracy: 0.9950\n",
            "Epoch 87/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.4441 - accuracy: 0.9979 - val_loss: 8.0465 - val_accuracy: 0.9950\n",
            "Epoch 88/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.3203 - accuracy: 0.9980 - val_loss: 8.8517 - val_accuracy: 0.9957\n",
            "Epoch 89/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 1.3531 - accuracy: 0.9982 - val_loss: 7.6671 - val_accuracy: 0.9957\n",
            "Epoch 90/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 1.2621 - accuracy: 0.9982 - val_loss: 8.6291 - val_accuracy: 0.9957\n",
            "Epoch 91/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.1588 - accuracy: 0.9984 - val_loss: 7.7484 - val_accuracy: 0.9950\n",
            "Epoch 92/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 1.2778 - accuracy: 0.9979 - val_loss: 7.7575 - val_accuracy: 0.9957\n",
            "Epoch 93/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 1.1044 - accuracy: 0.9982 - val_loss: 8.2006 - val_accuracy: 0.9950\n",
            "Epoch 94/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.1107 - accuracy: 0.9982 - val_loss: 8.0654 - val_accuracy: 0.9950\n",
            "Epoch 95/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.0375 - accuracy: 0.9982 - val_loss: 8.3039 - val_accuracy: 0.9950\n",
            "Epoch 96/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.0068 - accuracy: 0.9982 - val_loss: 8.0686 - val_accuracy: 0.9950\n",
            "Epoch 97/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.0251 - accuracy: 0.9979 - val_loss: 8.1099 - val_accuracy: 0.9950\n",
            "Epoch 98/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.8948 - accuracy: 0.9986 - val_loss: 8.1063 - val_accuracy: 0.9950\n",
            "Epoch 99/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.8994 - accuracy: 0.9982 - val_loss: 7.9776 - val_accuracy: 0.9950\n",
            "Epoch 100/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.8821 - accuracy: 0.9980 - val_loss: 7.6803 - val_accuracy: 0.9950\n",
            "Epoch 101/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.8699 - accuracy: 0.9980 - val_loss: 7.6340 - val_accuracy: 0.9950\n",
            "Epoch 102/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.8602 - accuracy: 0.9988 - val_loss: 8.3935 - val_accuracy: 0.9950\n",
            "Epoch 103/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.8591 - accuracy: 0.9984 - val_loss: 7.7074 - val_accuracy: 0.9950\n",
            "Epoch 104/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.8308 - accuracy: 0.9980 - val_loss: 7.5758 - val_accuracy: 0.9950\n",
            "Epoch 105/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.8490 - accuracy: 0.9979 - val_loss: 7.7932 - val_accuracy: 0.9957\n",
            "Epoch 106/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7990 - accuracy: 0.9986 - val_loss: 7.9448 - val_accuracy: 0.9957\n",
            "Epoch 107/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.7818 - accuracy: 0.9986 - val_loss: 7.8999 - val_accuracy: 0.9950\n",
            "Epoch 108/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.7409 - accuracy: 0.9984 - val_loss: 7.7752 - val_accuracy: 0.9950\n",
            "Epoch 109/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.7370 - accuracy: 0.9984 - val_loss: 7.8014 - val_accuracy: 0.9943\n",
            "Epoch 110/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.7068 - accuracy: 0.9984 - val_loss: 7.9894 - val_accuracy: 0.9950\n",
            "Epoch 111/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6970 - accuracy: 0.9982 - val_loss: 7.8401 - val_accuracy: 0.9957\n",
            "Epoch 112/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.6910 - accuracy: 0.9986 - val_loss: 7.6841 - val_accuracy: 0.9950\n",
            "Epoch 113/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6992 - accuracy: 0.9988 - val_loss: 7.7543 - val_accuracy: 0.9943\n",
            "Epoch 114/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6796 - accuracy: 0.9993 - val_loss: 7.9447 - val_accuracy: 0.9950\n",
            "Epoch 115/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6567 - accuracy: 0.9989 - val_loss: 7.3969 - val_accuracy: 0.9950\n",
            "Epoch 116/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.6171 - accuracy: 0.9991 - val_loss: 7.6519 - val_accuracy: 0.9957\n",
            "Epoch 117/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6081 - accuracy: 0.9989 - val_loss: 7.6874 - val_accuracy: 0.9950\n",
            "Epoch 118/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6494 - accuracy: 0.9989 - val_loss: 7.6024 - val_accuracy: 0.9950\n",
            "Epoch 119/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6155 - accuracy: 0.9991 - val_loss: 7.6480 - val_accuracy: 0.9950\n",
            "Epoch 120/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6099 - accuracy: 0.9984 - val_loss: 8.0577 - val_accuracy: 0.9950\n",
            "Epoch 121/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.6272 - accuracy: 0.9991 - val_loss: 7.7157 - val_accuracy: 0.9950\n",
            "Epoch 122/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5789 - accuracy: 0.9986 - val_loss: 7.7918 - val_accuracy: 0.9950\n",
            "Epoch 123/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5615 - accuracy: 0.9991 - val_loss: 7.7246 - val_accuracy: 0.9950\n",
            "Epoch 124/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5458 - accuracy: 0.9984 - val_loss: 7.5003 - val_accuracy: 0.9950\n",
            "Epoch 125/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5634 - accuracy: 0.9982 - val_loss: 7.6328 - val_accuracy: 0.9950\n",
            "Epoch 126/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5839 - accuracy: 0.9993 - val_loss: 7.6519 - val_accuracy: 0.9950\n",
            "Epoch 127/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5615 - accuracy: 0.9988 - val_loss: 7.5702 - val_accuracy: 0.9950\n",
            "Epoch 128/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5084 - accuracy: 0.9993 - val_loss: 7.9377 - val_accuracy: 0.9950\n",
            "Epoch 129/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4899 - accuracy: 0.9991 - val_loss: 7.5787 - val_accuracy: 0.9950\n",
            "Epoch 130/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4754 - accuracy: 0.9982 - val_loss: 7.9460 - val_accuracy: 0.9957\n",
            "Epoch 131/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.4677 - accuracy: 0.9996 - val_loss: 7.5972 - val_accuracy: 0.9950\n",
            "Epoch 132/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5055 - accuracy: 0.9989 - val_loss: 7.5667 - val_accuracy: 0.9950\n",
            "Epoch 133/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5251 - accuracy: 0.9986 - val_loss: 7.6037 - val_accuracy: 0.9950\n",
            "Epoch 134/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.5175 - accuracy: 0.9986 - val_loss: 7.8539 - val_accuracy: 0.9950\n",
            "Epoch 135/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4961 - accuracy: 0.9993 - val_loss: 7.5573 - val_accuracy: 0.9950\n",
            "Epoch 136/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4694 - accuracy: 0.9986 - val_loss: 7.5291 - val_accuracy: 0.9943\n",
            "Epoch 137/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4633 - accuracy: 0.9991 - val_loss: 7.6878 - val_accuracy: 0.9950\n",
            "Epoch 138/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4660 - accuracy: 0.9991 - val_loss: 7.7401 - val_accuracy: 0.9950\n",
            "Epoch 139/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4798 - accuracy: 0.9989 - val_loss: 7.7653 - val_accuracy: 0.9950\n",
            "Epoch 140/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.4699 - accuracy: 0.9993 - val_loss: 7.4148 - val_accuracy: 0.9950\n",
            "Epoch 141/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4638 - accuracy: 0.9991 - val_loss: 7.6509 - val_accuracy: 0.9950\n",
            "Epoch 142/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4617 - accuracy: 0.9991 - val_loss: 7.5402 - val_accuracy: 0.9950\n",
            "Epoch 143/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4463 - accuracy: 0.9989 - val_loss: 7.8122 - val_accuracy: 0.9950\n",
            "Epoch 144/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4127 - accuracy: 0.9995 - val_loss: 7.7648 - val_accuracy: 0.9950\n",
            "Epoch 145/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4212 - accuracy: 0.9993 - val_loss: 7.6817 - val_accuracy: 0.9950\n",
            "Epoch 146/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4407 - accuracy: 0.9991 - val_loss: 7.5810 - val_accuracy: 0.9950\n",
            "Epoch 147/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.4322 - accuracy: 0.9991 - val_loss: 7.5812 - val_accuracy: 0.9943\n",
            "Epoch 148/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4537 - accuracy: 0.9991 - val_loss: 7.5552 - val_accuracy: 0.9950\n",
            "Epoch 149/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.4549 - accuracy: 0.9991 - val_loss: 7.6053 - val_accuracy: 0.9950\n",
            "Epoch 150/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4249 - accuracy: 0.9991 - val_loss: 7.6288 - val_accuracy: 0.9950\n",
            "Epoch 151/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.4454 - accuracy: 0.9995 - val_loss: 7.5056 - val_accuracy: 0.9950\n",
            "Epoch 152/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4269 - accuracy: 0.9993 - val_loss: 7.5114 - val_accuracy: 0.9950\n",
            "Epoch 153/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4206 - accuracy: 0.9991 - val_loss: 7.4685 - val_accuracy: 0.9950\n",
            "Epoch 154/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3799 - accuracy: 0.9991 - val_loss: 7.6238 - val_accuracy: 0.9950\n",
            "Epoch 155/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3816 - accuracy: 0.9988 - val_loss: 7.9853 - val_accuracy: 0.9950\n",
            "Epoch 156/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4044 - accuracy: 0.9995 - val_loss: 7.6840 - val_accuracy: 0.9950\n",
            "Epoch 157/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3994 - accuracy: 0.9989 - val_loss: 7.5664 - val_accuracy: 0.9950\n",
            "Epoch 158/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4158 - accuracy: 0.9988 - val_loss: 7.6291 - val_accuracy: 0.9950\n",
            "Epoch 159/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.3944 - accuracy: 0.9986 - val_loss: 7.5092 - val_accuracy: 0.9950\n",
            "Epoch 160/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3872 - accuracy: 0.9991 - val_loss: 7.5816 - val_accuracy: 0.9950\n",
            "Epoch 161/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3880 - accuracy: 0.9995 - val_loss: 7.3259 - val_accuracy: 0.9950\n",
            "Epoch 162/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.4192 - accuracy: 0.9991 - val_loss: 7.4546 - val_accuracy: 0.9950\n",
            "Epoch 163/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3662 - accuracy: 0.9991 - val_loss: 8.3164 - val_accuracy: 0.9950\n",
            "Epoch 164/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.4022 - accuracy: 0.9993 - val_loss: 7.4196 - val_accuracy: 0.9950\n",
            "Epoch 165/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3845 - accuracy: 0.9991 - val_loss: 7.3906 - val_accuracy: 0.9950\n",
            "Epoch 166/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3868 - accuracy: 0.9995 - val_loss: 7.6718 - val_accuracy: 0.9950\n",
            "Epoch 167/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3838 - accuracy: 0.9989 - val_loss: 7.8396 - val_accuracy: 0.9950\n",
            "Epoch 168/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3939 - accuracy: 0.9989 - val_loss: 7.5499 - val_accuracy: 0.9950\n",
            "Epoch 169/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.3531 - accuracy: 0.9995 - val_loss: 7.4643 - val_accuracy: 0.9950\n",
            "Epoch 170/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.3558 - accuracy: 0.9989 - val_loss: 7.5282 - val_accuracy: 0.9950\n",
            "Epoch 171/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3627 - accuracy: 0.9995 - val_loss: 7.6714 - val_accuracy: 0.9950\n",
            "Epoch 172/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3702 - accuracy: 0.9988 - val_loss: 7.5400 - val_accuracy: 0.9950\n",
            "Epoch 173/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.3577 - accuracy: 0.9991 - val_loss: 7.3266 - val_accuracy: 0.9950\n",
            "Epoch 174/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3765 - accuracy: 0.9993 - val_loss: 7.4440 - val_accuracy: 0.9950\n",
            "Epoch 175/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3609 - accuracy: 0.9988 - val_loss: 7.3397 - val_accuracy: 0.9950\n",
            "Epoch 176/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3496 - accuracy: 0.9996 - val_loss: 7.3585 - val_accuracy: 0.9950\n",
            "Epoch 177/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3396 - accuracy: 0.9995 - val_loss: 7.4286 - val_accuracy: 0.9950\n",
            "Epoch 178/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.3413 - accuracy: 0.9993 - val_loss: 7.6021 - val_accuracy: 0.9950\n",
            "Epoch 179/500\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.3565 - accuracy: 0.9986 - val_loss: 7.4860 - val_accuracy: 0.9950\n",
            "Epoch 180/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3505 - accuracy: 0.9993 - val_loss: 7.3362 - val_accuracy: 0.9950\n",
            "Epoch 181/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3630 - accuracy: 0.9993 - val_loss: 7.4462 - val_accuracy: 0.9950\n",
            "Epoch 182/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3512 - accuracy: 0.9996 - val_loss: 7.1687 - val_accuracy: 0.9950\n",
            "Epoch 183/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3493 - accuracy: 0.9989 - val_loss: 7.3503 - val_accuracy: 0.9950\n",
            "Epoch 184/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3397 - accuracy: 0.9993 - val_loss: 7.3189 - val_accuracy: 0.9950\n",
            "Epoch 185/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3132 - accuracy: 0.9989 - val_loss: 7.4445 - val_accuracy: 0.9950\n",
            "Epoch 186/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3350 - accuracy: 0.9991 - val_loss: 7.3977 - val_accuracy: 0.9950\n",
            "Epoch 187/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3543 - accuracy: 0.9993 - val_loss: 7.3745 - val_accuracy: 0.9950\n",
            "Epoch 188/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3500 - accuracy: 0.9991 - val_loss: 7.3579 - val_accuracy: 0.9950\n",
            "Epoch 189/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3362 - accuracy: 0.9993 - val_loss: 7.5004 - val_accuracy: 0.9950\n",
            "Epoch 190/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3708 - accuracy: 0.9989 - val_loss: 7.5308 - val_accuracy: 0.9950\n",
            "Epoch 191/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3331 - accuracy: 0.9991 - val_loss: 7.1562 - val_accuracy: 0.9950\n",
            "Epoch 192/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3283 - accuracy: 0.9989 - val_loss: 7.2032 - val_accuracy: 0.9950\n",
            "Epoch 193/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3280 - accuracy: 0.9996 - val_loss: 7.3818 - val_accuracy: 0.9950\n",
            "Epoch 194/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3273 - accuracy: 0.9989 - val_loss: 7.4426 - val_accuracy: 0.9950\n",
            "Epoch 195/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3097 - accuracy: 0.9996 - val_loss: 7.6140 - val_accuracy: 0.9950\n",
            "Epoch 196/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3252 - accuracy: 0.9991 - val_loss: 7.5653 - val_accuracy: 0.9950\n",
            "Epoch 197/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3366 - accuracy: 0.9995 - val_loss: 7.2364 - val_accuracy: 0.9950\n",
            "Epoch 198/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3324 - accuracy: 0.9995 - val_loss: 7.4363 - val_accuracy: 0.9950\n",
            "Epoch 199/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3331 - accuracy: 0.9993 - val_loss: 7.1626 - val_accuracy: 0.9950\n",
            "Epoch 200/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3162 - accuracy: 0.9995 - val_loss: 7.1899 - val_accuracy: 0.9950\n",
            "Epoch 201/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3122 - accuracy: 0.9993 - val_loss: 7.3634 - val_accuracy: 0.9950\n",
            "Epoch 202/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3106 - accuracy: 0.9995 - val_loss: 7.2983 - val_accuracy: 0.9950\n",
            "Epoch 203/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3116 - accuracy: 0.9991 - val_loss: 7.4449 - val_accuracy: 0.9950\n",
            "Epoch 204/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3302 - accuracy: 0.9993 - val_loss: 7.3067 - val_accuracy: 0.9950\n",
            "Epoch 205/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3081 - accuracy: 0.9993 - val_loss: 7.3707 - val_accuracy: 0.9950\n",
            "Epoch 206/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2974 - accuracy: 0.9991 - val_loss: 7.1544 - val_accuracy: 0.9950\n",
            "Epoch 207/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3222 - accuracy: 0.9993 - val_loss: 7.3584 - val_accuracy: 0.9950\n",
            "Epoch 208/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3125 - accuracy: 0.9993 - val_loss: 7.3282 - val_accuracy: 0.9950\n",
            "Epoch 209/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3150 - accuracy: 0.9991 - val_loss: 7.3925 - val_accuracy: 0.9950\n",
            "Epoch 210/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3074 - accuracy: 0.9995 - val_loss: 7.2421 - val_accuracy: 0.9950\n",
            "Epoch 211/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3192 - accuracy: 0.9998 - val_loss: 7.1090 - val_accuracy: 0.9950\n",
            "Epoch 212/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3177 - accuracy: 0.9991 - val_loss: 7.4715 - val_accuracy: 0.9950\n",
            "Epoch 213/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3256 - accuracy: 0.9991 - val_loss: 7.5699 - val_accuracy: 0.9950\n",
            "Epoch 214/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3155 - accuracy: 0.9996 - val_loss: 7.4113 - val_accuracy: 0.9950\n",
            "Epoch 215/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.3066 - accuracy: 0.9993 - val_loss: 7.3908 - val_accuracy: 0.9950\n",
            "Epoch 216/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3039 - accuracy: 0.9991 - val_loss: 7.2975 - val_accuracy: 0.9950\n",
            "Epoch 217/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3073 - accuracy: 0.9993 - val_loss: 7.3416 - val_accuracy: 0.9950\n",
            "Epoch 218/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2992 - accuracy: 0.9991 - val_loss: 7.2052 - val_accuracy: 0.9950\n",
            "Epoch 219/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3031 - accuracy: 0.9991 - val_loss: 7.2086 - val_accuracy: 0.9950\n",
            "Epoch 220/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3029 - accuracy: 0.9995 - val_loss: 7.3284 - val_accuracy: 0.9950\n",
            "Epoch 221/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3002 - accuracy: 0.9993 - val_loss: 7.3335 - val_accuracy: 0.9950\n",
            "Epoch 222/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3017 - accuracy: 0.9988 - val_loss: 7.2716 - val_accuracy: 0.9950\n",
            "Epoch 223/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2891 - accuracy: 0.9991 - val_loss: 7.3286 - val_accuracy: 0.9950\n",
            "Epoch 224/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2867 - accuracy: 0.9996 - val_loss: 7.3232 - val_accuracy: 0.9950\n",
            "Epoch 225/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3061 - accuracy: 0.9991 - val_loss: 7.1944 - val_accuracy: 0.9950\n",
            "Epoch 226/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2988 - accuracy: 0.9991 - val_loss: 7.3607 - val_accuracy: 0.9950\n",
            "Epoch 227/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2828 - accuracy: 0.9991 - val_loss: 7.2300 - val_accuracy: 0.9950\n",
            "Epoch 228/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2720 - accuracy: 0.9996 - val_loss: 7.2984 - val_accuracy: 0.9950\n",
            "Epoch 229/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2858 - accuracy: 0.9996 - val_loss: 7.1331 - val_accuracy: 0.9950\n",
            "Epoch 230/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2882 - accuracy: 0.9995 - val_loss: 7.3459 - val_accuracy: 0.9950\n",
            "Epoch 231/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2968 - accuracy: 0.9993 - val_loss: 7.3868 - val_accuracy: 0.9950\n",
            "Epoch 232/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3048 - accuracy: 0.9995 - val_loss: 7.2323 - val_accuracy: 0.9950\n",
            "Epoch 233/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.3070 - accuracy: 0.9995 - val_loss: 7.3181 - val_accuracy: 0.9950\n",
            "Epoch 234/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2767 - accuracy: 0.9986 - val_loss: 7.6846 - val_accuracy: 0.9950\n",
            "Epoch 235/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2886 - accuracy: 0.9995 - val_loss: 7.3975 - val_accuracy: 0.9950\n",
            "Epoch 236/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2889 - accuracy: 0.9991 - val_loss: 7.1475 - val_accuracy: 0.9950\n",
            "Epoch 237/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2769 - accuracy: 0.9996 - val_loss: 7.2250 - val_accuracy: 0.9950\n",
            "Epoch 238/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2978 - accuracy: 0.9993 - val_loss: 7.3166 - val_accuracy: 0.9950\n",
            "Epoch 239/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2810 - accuracy: 0.9996 - val_loss: 7.2537 - val_accuracy: 0.9950\n",
            "Epoch 240/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2709 - accuracy: 0.9995 - val_loss: 7.3751 - val_accuracy: 0.9950\n",
            "Epoch 241/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2835 - accuracy: 0.9996 - val_loss: 7.2694 - val_accuracy: 0.9950\n",
            "Epoch 242/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2836 - accuracy: 0.9991 - val_loss: 7.2254 - val_accuracy: 0.9950\n",
            "Epoch 243/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2821 - accuracy: 0.9991 - val_loss: 7.2073 - val_accuracy: 0.9950\n",
            "Epoch 244/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2852 - accuracy: 0.9993 - val_loss: 7.3998 - val_accuracy: 0.9950\n",
            "Epoch 245/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2770 - accuracy: 0.9996 - val_loss: 7.1892 - val_accuracy: 0.9950\n",
            "Epoch 246/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2645 - accuracy: 0.9991 - val_loss: 7.2833 - val_accuracy: 0.9950\n",
            "Epoch 247/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2686 - accuracy: 0.9993 - val_loss: 7.1750 - val_accuracy: 0.9950\n",
            "Epoch 248/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2821 - accuracy: 0.9996 - val_loss: 7.1261 - val_accuracy: 0.9950\n",
            "Epoch 249/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2781 - accuracy: 0.9993 - val_loss: 7.2493 - val_accuracy: 0.9950\n",
            "Epoch 250/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2747 - accuracy: 0.9993 - val_loss: 7.1616 - val_accuracy: 0.9950\n",
            "Epoch 251/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2798 - accuracy: 0.9995 - val_loss: 7.2563 - val_accuracy: 0.9950\n",
            "Epoch 252/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2679 - accuracy: 0.9995 - val_loss: 7.2536 - val_accuracy: 0.9950\n",
            "Epoch 253/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2790 - accuracy: 0.9996 - val_loss: 7.2222 - val_accuracy: 0.9950\n",
            "Epoch 254/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2825 - accuracy: 0.9991 - val_loss: 7.2408 - val_accuracy: 0.9950\n",
            "Epoch 255/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2842 - accuracy: 0.9989 - val_loss: 7.2253 - val_accuracy: 0.9950\n",
            "Epoch 256/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2694 - accuracy: 0.9991 - val_loss: 7.4256 - val_accuracy: 0.9950\n",
            "Epoch 257/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2617 - accuracy: 0.9995 - val_loss: 7.1870 - val_accuracy: 0.9950\n",
            "Epoch 258/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2623 - accuracy: 0.9995 - val_loss: 7.3120 - val_accuracy: 0.9950\n",
            "Epoch 259/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2707 - accuracy: 0.9995 - val_loss: 7.1580 - val_accuracy: 0.9950\n",
            "Epoch 260/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2747 - accuracy: 0.9995 - val_loss: 7.2838 - val_accuracy: 0.9950\n",
            "Epoch 261/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2753 - accuracy: 0.9991 - val_loss: 7.0705 - val_accuracy: 0.9950\n",
            "Epoch 262/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2741 - accuracy: 0.9995 - val_loss: 7.1366 - val_accuracy: 0.9950\n",
            "Epoch 263/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2644 - accuracy: 0.9991 - val_loss: 7.0810 - val_accuracy: 0.9950\n",
            "Epoch 264/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2646 - accuracy: 0.9993 - val_loss: 7.0902 - val_accuracy: 0.9950\n",
            "Epoch 265/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2645 - accuracy: 0.9991 - val_loss: 7.1528 - val_accuracy: 0.9950\n",
            "Epoch 266/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2680 - accuracy: 0.9993 - val_loss: 7.2032 - val_accuracy: 0.9950\n",
            "Epoch 267/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2701 - accuracy: 0.9993 - val_loss: 7.1062 - val_accuracy: 0.9950\n",
            "Epoch 268/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2403 - accuracy: 0.9991 - val_loss: 7.2463 - val_accuracy: 0.9950\n",
            "Epoch 269/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2611 - accuracy: 0.9993 - val_loss: 7.2363 - val_accuracy: 0.9950\n",
            "Epoch 270/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2652 - accuracy: 0.9995 - val_loss: 7.1910 - val_accuracy: 0.9950\n",
            "Epoch 271/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2477 - accuracy: 0.9993 - val_loss: 7.3133 - val_accuracy: 0.9950\n",
            "Epoch 272/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2596 - accuracy: 0.9995 - val_loss: 7.1332 - val_accuracy: 0.9950\n",
            "Epoch 273/500\n",
            "352/352 [==============================] - 21s 60ms/step - loss: 0.2665 - accuracy: 0.9998 - val_loss: 7.1714 - val_accuracy: 0.9950\n",
            "Epoch 274/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2515 - accuracy: 0.9996 - val_loss: 7.2523 - val_accuracy: 0.9950\n",
            "Epoch 275/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2617 - accuracy: 0.9993 - val_loss: 7.0579 - val_accuracy: 0.9950\n",
            "Epoch 276/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2494 - accuracy: 0.9989 - val_loss: 7.2815 - val_accuracy: 0.9950\n",
            "Epoch 277/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2443 - accuracy: 0.9996 - val_loss: 7.2128 - val_accuracy: 0.9950\n",
            "Epoch 278/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2509 - accuracy: 0.9996 - val_loss: 7.1744 - val_accuracy: 0.9950\n",
            "Epoch 279/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2590 - accuracy: 0.9995 - val_loss: 7.2076 - val_accuracy: 0.9950\n",
            "Epoch 280/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2388 - accuracy: 0.9996 - val_loss: 7.1612 - val_accuracy: 0.9950\n",
            "Epoch 281/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2509 - accuracy: 0.9991 - val_loss: 7.1298 - val_accuracy: 0.9950\n",
            "Epoch 282/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2573 - accuracy: 0.9993 - val_loss: 7.2216 - val_accuracy: 0.9950\n",
            "Epoch 283/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2463 - accuracy: 0.9993 - val_loss: 7.2305 - val_accuracy: 0.9950\n",
            "Epoch 284/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2425 - accuracy: 0.9991 - val_loss: 7.1490 - val_accuracy: 0.9950\n",
            "Epoch 285/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2470 - accuracy: 0.9996 - val_loss: 7.1482 - val_accuracy: 0.9950\n",
            "Epoch 286/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2474 - accuracy: 0.9995 - val_loss: 7.2903 - val_accuracy: 0.9950\n",
            "Epoch 287/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2504 - accuracy: 0.9996 - val_loss: 7.2472 - val_accuracy: 0.9950\n",
            "Epoch 288/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2392 - accuracy: 0.9996 - val_loss: 7.3046 - val_accuracy: 0.9950\n",
            "Epoch 289/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2527 - accuracy: 0.9993 - val_loss: 7.2703 - val_accuracy: 0.9950\n",
            "Epoch 290/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2422 - accuracy: 0.9996 - val_loss: 7.1997 - val_accuracy: 0.9950\n",
            "Epoch 291/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2491 - accuracy: 0.9996 - val_loss: 7.1278 - val_accuracy: 0.9950\n",
            "Epoch 292/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2526 - accuracy: 0.9991 - val_loss: 7.2302 - val_accuracy: 0.9950\n",
            "Epoch 293/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2378 - accuracy: 0.9993 - val_loss: 6.9892 - val_accuracy: 0.9950\n",
            "Epoch 294/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2481 - accuracy: 0.9989 - val_loss: 7.1110 - val_accuracy: 0.9950\n",
            "Epoch 295/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2397 - accuracy: 0.9995 - val_loss: 7.2570 - val_accuracy: 0.9950\n",
            "Epoch 296/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2506 - accuracy: 0.9993 - val_loss: 7.2007 - val_accuracy: 0.9950\n",
            "Epoch 297/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2215 - accuracy: 0.9991 - val_loss: 7.0468 - val_accuracy: 0.9950\n",
            "Epoch 298/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2300 - accuracy: 0.9995 - val_loss: 7.5148 - val_accuracy: 0.9957\n",
            "Epoch 299/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2411 - accuracy: 0.9996 - val_loss: 7.1169 - val_accuracy: 0.9950\n",
            "Epoch 300/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2303 - accuracy: 0.9996 - val_loss: 7.2365 - val_accuracy: 0.9950\n",
            "Epoch 301/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2278 - accuracy: 0.9996 - val_loss: 7.2472 - val_accuracy: 0.9950\n",
            "Epoch 302/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2318 - accuracy: 0.9995 - val_loss: 7.1608 - val_accuracy: 0.9950\n",
            "Epoch 303/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2351 - accuracy: 0.9996 - val_loss: 7.1574 - val_accuracy: 0.9950\n",
            "Epoch 304/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2305 - accuracy: 0.9995 - val_loss: 7.1144 - val_accuracy: 0.9950\n",
            "Epoch 305/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2311 - accuracy: 0.9996 - val_loss: 7.6097 - val_accuracy: 0.9957\n",
            "Epoch 306/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2434 - accuracy: 0.9989 - val_loss: 7.1153 - val_accuracy: 0.9950\n",
            "Epoch 307/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2372 - accuracy: 0.9995 - val_loss: 7.0780 - val_accuracy: 0.9950\n",
            "Epoch 308/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2338 - accuracy: 0.9995 - val_loss: 7.1732 - val_accuracy: 0.9950\n",
            "Epoch 309/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2388 - accuracy: 0.9995 - val_loss: 7.1703 - val_accuracy: 0.9950\n",
            "Epoch 310/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2381 - accuracy: 0.9998 - val_loss: 7.0120 - val_accuracy: 0.9950\n",
            "Epoch 311/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2298 - accuracy: 0.9991 - val_loss: 7.1662 - val_accuracy: 0.9950\n",
            "Epoch 312/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2345 - accuracy: 0.9996 - val_loss: 7.2036 - val_accuracy: 0.9950\n",
            "Epoch 313/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2321 - accuracy: 0.9993 - val_loss: 7.0819 - val_accuracy: 0.9950\n",
            "Epoch 314/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2270 - accuracy: 0.9993 - val_loss: 7.3150 - val_accuracy: 0.9943\n",
            "Epoch 315/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.2257 - accuracy: 0.9993 - val_loss: 7.2402 - val_accuracy: 0.9950\n",
            "Epoch 316/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2287 - accuracy: 0.9996 - val_loss: 7.1084 - val_accuracy: 0.9950\n",
            "Epoch 317/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2225 - accuracy: 0.9995 - val_loss: 7.0543 - val_accuracy: 0.9950\n",
            "Epoch 318/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2279 - accuracy: 0.9993 - val_loss: 7.1695 - val_accuracy: 0.9950\n",
            "Epoch 319/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2234 - accuracy: 0.9993 - val_loss: 7.2587 - val_accuracy: 0.9950\n",
            "Epoch 320/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2422 - accuracy: 0.9989 - val_loss: 7.1909 - val_accuracy: 0.9950\n",
            "Epoch 321/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.2272 - accuracy: 0.9993 - val_loss: 7.0663 - val_accuracy: 0.9950\n",
            "Epoch 322/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2344 - accuracy: 0.9995 - val_loss: 7.0761 - val_accuracy: 0.9950\n",
            "Epoch 323/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2154 - accuracy: 0.9995 - val_loss: 7.1402 - val_accuracy: 0.9950\n",
            "Epoch 324/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2245 - accuracy: 0.9998 - val_loss: 7.0961 - val_accuracy: 0.9950\n",
            "Epoch 325/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2153 - accuracy: 0.9995 - val_loss: 7.1399 - val_accuracy: 0.9950\n",
            "Epoch 326/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2246 - accuracy: 0.9996 - val_loss: 6.8688 - val_accuracy: 0.9950\n",
            "Epoch 327/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2266 - accuracy: 0.9993 - val_loss: 7.1068 - val_accuracy: 0.9950\n",
            "Epoch 328/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2226 - accuracy: 0.9993 - val_loss: 7.3636 - val_accuracy: 0.9950\n",
            "Epoch 329/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2241 - accuracy: 0.9988 - val_loss: 7.0847 - val_accuracy: 0.9950\n",
            "Epoch 330/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.2180 - accuracy: 0.9995 - val_loss: 7.0992 - val_accuracy: 0.9950\n",
            "Epoch 331/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2135 - accuracy: 0.9993 - val_loss: 7.2260 - val_accuracy: 0.9950\n",
            "Epoch 332/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2232 - accuracy: 0.9995 - val_loss: 6.9292 - val_accuracy: 0.9950\n",
            "Epoch 333/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2241 - accuracy: 0.9996 - val_loss: 7.0328 - val_accuracy: 0.9950\n",
            "Epoch 334/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2071 - accuracy: 0.9995 - val_loss: 7.0400 - val_accuracy: 0.9950\n",
            "Epoch 335/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2276 - accuracy: 0.9993 - val_loss: 7.1114 - val_accuracy: 0.9950\n",
            "Epoch 336/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.2262 - accuracy: 0.9993 - val_loss: 7.1797 - val_accuracy: 0.9950\n",
            "Epoch 337/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2258 - accuracy: 0.9993 - val_loss: 7.0716 - val_accuracy: 0.9950\n",
            "Epoch 338/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2136 - accuracy: 0.9995 - val_loss: 7.0521 - val_accuracy: 0.9950\n",
            "Epoch 339/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2098 - accuracy: 0.9995 - val_loss: 7.0954 - val_accuracy: 0.9950\n",
            "Epoch 340/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2100 - accuracy: 0.9996 - val_loss: 7.0290 - val_accuracy: 0.9950\n",
            "Epoch 341/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2091 - accuracy: 0.9993 - val_loss: 7.0885 - val_accuracy: 0.9950\n",
            "Epoch 342/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2122 - accuracy: 0.9993 - val_loss: 7.2061 - val_accuracy: 0.9950\n",
            "Epoch 343/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2043 - accuracy: 0.9995 - val_loss: 6.8835 - val_accuracy: 0.9950\n",
            "Epoch 344/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2141 - accuracy: 0.9993 - val_loss: 7.1257 - val_accuracy: 0.9950\n",
            "Epoch 345/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2147 - accuracy: 0.9993 - val_loss: 7.1122 - val_accuracy: 0.9950\n",
            "Epoch 346/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2113 - accuracy: 0.9995 - val_loss: 7.1208 - val_accuracy: 0.9950\n",
            "Epoch 347/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2103 - accuracy: 0.9996 - val_loss: 7.1447 - val_accuracy: 0.9950\n",
            "Epoch 348/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2049 - accuracy: 0.9995 - val_loss: 6.9768 - val_accuracy: 0.9950\n",
            "Epoch 349/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.2031 - accuracy: 0.9993 - val_loss: 7.2460 - val_accuracy: 0.9950\n",
            "Epoch 350/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2016 - accuracy: 0.9996 - val_loss: 7.0561 - val_accuracy: 0.9950\n",
            "Epoch 351/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2053 - accuracy: 0.9993 - val_loss: 7.0291 - val_accuracy: 0.9950\n",
            "Epoch 352/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.2050 - accuracy: 0.9996 - val_loss: 7.1325 - val_accuracy: 0.9950\n",
            "Epoch 353/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2090 - accuracy: 0.9996 - val_loss: 7.0466 - val_accuracy: 0.9950\n",
            "Epoch 354/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2037 - accuracy: 0.9996 - val_loss: 7.1440 - val_accuracy: 0.9950\n",
            "Epoch 355/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.2101 - accuracy: 0.9995 - val_loss: 7.1845 - val_accuracy: 0.9950\n",
            "Epoch 356/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2041 - accuracy: 0.9996 - val_loss: 7.0483 - val_accuracy: 0.9950\n",
            "Epoch 357/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2023 - accuracy: 0.9996 - val_loss: 7.0693 - val_accuracy: 0.9950\n",
            "Epoch 358/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.1999 - accuracy: 0.9995 - val_loss: 7.1063 - val_accuracy: 0.9950\n",
            "Epoch 359/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2065 - accuracy: 0.9998 - val_loss: 7.0006 - val_accuracy: 0.9950\n",
            "Epoch 360/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2026 - accuracy: 0.9995 - val_loss: 7.0782 - val_accuracy: 0.9950\n",
            "Epoch 361/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.2058 - accuracy: 0.9993 - val_loss: 7.1687 - val_accuracy: 0.9950\n",
            "Epoch 362/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2042 - accuracy: 0.9996 - val_loss: 7.1638 - val_accuracy: 0.9950\n",
            "Epoch 363/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2020 - accuracy: 0.9995 - val_loss: 7.1179 - val_accuracy: 0.9950\n",
            "Epoch 364/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1998 - accuracy: 0.9995 - val_loss: 7.2540 - val_accuracy: 0.9950\n",
            "Epoch 365/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1969 - accuracy: 0.9996 - val_loss: 7.2366 - val_accuracy: 0.9950\n",
            "Epoch 366/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2003 - accuracy: 0.9995 - val_loss: 7.1041 - val_accuracy: 0.9950\n",
            "Epoch 367/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1925 - accuracy: 0.9998 - val_loss: 7.1565 - val_accuracy: 0.9950\n",
            "Epoch 368/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1979 - accuracy: 0.9995 - val_loss: 7.1352 - val_accuracy: 0.9950\n",
            "Epoch 369/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1981 - accuracy: 0.9995 - val_loss: 7.1696 - val_accuracy: 0.9950\n",
            "Epoch 370/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1981 - accuracy: 0.9991 - val_loss: 7.1207 - val_accuracy: 0.9950\n",
            "Epoch 371/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1969 - accuracy: 0.9998 - val_loss: 7.1084 - val_accuracy: 0.9950\n",
            "Epoch 372/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1942 - accuracy: 0.9995 - val_loss: 7.0166 - val_accuracy: 0.9950\n",
            "Epoch 373/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1930 - accuracy: 0.9996 - val_loss: 7.0509 - val_accuracy: 0.9950\n",
            "Epoch 374/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1969 - accuracy: 0.9993 - val_loss: 7.1261 - val_accuracy: 0.9950\n",
            "Epoch 375/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1963 - accuracy: 0.9995 - val_loss: 7.1244 - val_accuracy: 0.9950\n",
            "Epoch 376/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2011 - accuracy: 0.9996 - val_loss: 7.0098 - val_accuracy: 0.9950\n",
            "Epoch 377/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1949 - accuracy: 0.9995 - val_loss: 7.1098 - val_accuracy: 0.9950\n",
            "Epoch 378/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1965 - accuracy: 0.9993 - val_loss: 7.1387 - val_accuracy: 0.9950\n",
            "Epoch 379/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.2006 - accuracy: 0.9996 - val_loss: 7.1180 - val_accuracy: 0.9950\n",
            "Epoch 380/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1943 - accuracy: 0.9996 - val_loss: 7.2200 - val_accuracy: 0.9950\n",
            "Epoch 381/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1943 - accuracy: 0.9996 - val_loss: 7.1409 - val_accuracy: 0.9950\n",
            "Epoch 382/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1957 - accuracy: 0.9995 - val_loss: 7.1257 - val_accuracy: 0.9950\n",
            "Epoch 383/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1894 - accuracy: 0.9995 - val_loss: 7.0927 - val_accuracy: 0.9950\n",
            "Epoch 384/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1909 - accuracy: 0.9998 - val_loss: 7.0979 - val_accuracy: 0.9950\n",
            "Epoch 385/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1932 - accuracy: 0.9993 - val_loss: 7.1718 - val_accuracy: 0.9950\n",
            "Epoch 386/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1957 - accuracy: 0.9993 - val_loss: 7.1061 - val_accuracy: 0.9950\n",
            "Epoch 387/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1885 - accuracy: 0.9996 - val_loss: 7.1129 - val_accuracy: 0.9950\n",
            "Epoch 388/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1852 - accuracy: 0.9995 - val_loss: 7.1443 - val_accuracy: 0.9950\n",
            "Epoch 389/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1871 - accuracy: 0.9995 - val_loss: 7.1352 - val_accuracy: 0.9950\n",
            "Epoch 390/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1833 - accuracy: 0.9991 - val_loss: 7.0508 - val_accuracy: 0.9950\n",
            "Epoch 391/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1924 - accuracy: 0.9993 - val_loss: 7.2492 - val_accuracy: 0.9950\n",
            "Epoch 392/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1949 - accuracy: 0.9995 - val_loss: 7.1269 - val_accuracy: 0.9950\n",
            "Epoch 393/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1848 - accuracy: 0.9995 - val_loss: 7.1330 - val_accuracy: 0.9950\n",
            "Epoch 394/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1887 - accuracy: 0.9998 - val_loss: 7.1257 - val_accuracy: 0.9950\n",
            "Epoch 395/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1801 - accuracy: 0.9996 - val_loss: 7.1221 - val_accuracy: 0.9950\n",
            "Epoch 396/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1882 - accuracy: 0.9995 - val_loss: 7.2354 - val_accuracy: 0.9950\n",
            "Epoch 397/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1850 - accuracy: 0.9998 - val_loss: 7.0492 - val_accuracy: 0.9950\n",
            "Epoch 398/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1900 - accuracy: 0.9993 - val_loss: 7.2029 - val_accuracy: 0.9950\n",
            "Epoch 399/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1869 - accuracy: 0.9995 - val_loss: 7.1725 - val_accuracy: 0.9950\n",
            "Epoch 400/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1832 - accuracy: 0.9995 - val_loss: 7.0585 - val_accuracy: 0.9950\n",
            "Epoch 401/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1886 - accuracy: 0.9996 - val_loss: 7.0860 - val_accuracy: 0.9950\n",
            "Epoch 402/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1899 - accuracy: 0.9996 - val_loss: 6.9989 - val_accuracy: 0.9950\n",
            "Epoch 403/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1774 - accuracy: 0.9993 - val_loss: 7.1012 - val_accuracy: 0.9950\n",
            "Epoch 404/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1889 - accuracy: 0.9998 - val_loss: 7.0764 - val_accuracy: 0.9950\n",
            "Epoch 405/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1799 - accuracy: 0.9996 - val_loss: 7.1458 - val_accuracy: 0.9950\n",
            "Epoch 406/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1777 - accuracy: 0.9996 - val_loss: 7.2193 - val_accuracy: 0.9950\n",
            "Epoch 407/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1782 - accuracy: 0.9991 - val_loss: 7.1094 - val_accuracy: 0.9950\n",
            "Epoch 408/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1866 - accuracy: 0.9995 - val_loss: 7.1533 - val_accuracy: 0.9950\n",
            "Epoch 409/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1811 - accuracy: 0.9995 - val_loss: 7.0625 - val_accuracy: 0.9950\n",
            "Epoch 410/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1796 - accuracy: 0.9993 - val_loss: 7.1175 - val_accuracy: 0.9950\n",
            "Epoch 411/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1835 - accuracy: 0.9996 - val_loss: 7.1213 - val_accuracy: 0.9950\n",
            "Epoch 412/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1798 - accuracy: 0.9996 - val_loss: 7.0948 - val_accuracy: 0.9950\n",
            "Epoch 413/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1807 - accuracy: 0.9995 - val_loss: 6.9143 - val_accuracy: 0.9950\n",
            "Epoch 414/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1806 - accuracy: 0.9995 - val_loss: 7.0718 - val_accuracy: 0.9950\n",
            "Epoch 415/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1810 - accuracy: 0.9996 - val_loss: 7.0163 - val_accuracy: 0.9950\n",
            "Epoch 416/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1747 - accuracy: 0.9996 - val_loss: 7.0657 - val_accuracy: 0.9950\n",
            "Epoch 417/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.1736 - accuracy: 0.9996 - val_loss: 7.0743 - val_accuracy: 0.9950\n",
            "Epoch 418/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1738 - accuracy: 0.9995 - val_loss: 7.0166 - val_accuracy: 0.9950\n",
            "Epoch 419/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1744 - accuracy: 0.9995 - val_loss: 7.0626 - val_accuracy: 0.9950\n",
            "Epoch 420/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.1752 - accuracy: 0.9998 - val_loss: 7.2549 - val_accuracy: 0.9950\n",
            "Epoch 421/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1759 - accuracy: 0.9998 - val_loss: 7.2215 - val_accuracy: 0.9950\n",
            "Epoch 422/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1814 - accuracy: 0.9996 - val_loss: 7.1234 - val_accuracy: 0.9950\n",
            "Epoch 423/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1725 - accuracy: 0.9998 - val_loss: 7.1418 - val_accuracy: 0.9950\n",
            "Epoch 424/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1719 - accuracy: 0.9996 - val_loss: 7.0671 - val_accuracy: 0.9950\n",
            "Epoch 425/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1712 - accuracy: 0.9996 - val_loss: 7.1838 - val_accuracy: 0.9950\n",
            "Epoch 426/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.1685 - accuracy: 0.9996 - val_loss: 7.0645 - val_accuracy: 0.9950\n",
            "Epoch 427/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1692 - accuracy: 0.9993 - val_loss: 7.1033 - val_accuracy: 0.9950\n",
            "Epoch 428/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1712 - accuracy: 0.9996 - val_loss: 7.1175 - val_accuracy: 0.9950\n",
            "Epoch 429/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1697 - accuracy: 0.9996 - val_loss: 7.0985 - val_accuracy: 0.9950\n",
            "Epoch 430/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1751 - accuracy: 0.9996 - val_loss: 7.1749 - val_accuracy: 0.9950\n",
            "Epoch 431/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1702 - accuracy: 0.9996 - val_loss: 7.1422 - val_accuracy: 0.9950\n",
            "Epoch 432/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.1711 - accuracy: 0.9996 - val_loss: 7.1131 - val_accuracy: 0.9950\n",
            "Epoch 433/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1692 - accuracy: 0.9998 - val_loss: 7.1138 - val_accuracy: 0.9950\n",
            "Epoch 434/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1691 - accuracy: 0.9993 - val_loss: 7.1031 - val_accuracy: 0.9950\n",
            "Epoch 435/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1698 - accuracy: 0.9996 - val_loss: 7.1267 - val_accuracy: 0.9950\n",
            "Epoch 436/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1688 - accuracy: 0.9995 - val_loss: 7.0351 - val_accuracy: 0.9950\n",
            "Epoch 437/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1653 - accuracy: 0.9998 - val_loss: 7.1002 - val_accuracy: 0.9950\n",
            "Epoch 438/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1678 - accuracy: 0.9995 - val_loss: 7.1298 - val_accuracy: 0.9950\n",
            "Epoch 439/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1665 - accuracy: 0.9996 - val_loss: 7.2375 - val_accuracy: 0.9950\n",
            "Epoch 440/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1702 - accuracy: 0.9996 - val_loss: 7.0993 - val_accuracy: 0.9950\n",
            "Epoch 441/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1645 - accuracy: 0.9996 - val_loss: 7.0917 - val_accuracy: 0.9950\n",
            "Epoch 442/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1623 - accuracy: 0.9996 - val_loss: 7.1463 - val_accuracy: 0.9950\n",
            "Epoch 443/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1660 - accuracy: 0.9993 - val_loss: 7.0758 - val_accuracy: 0.9950\n",
            "Epoch 444/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1669 - accuracy: 0.9996 - val_loss: 7.0842 - val_accuracy: 0.9950\n",
            "Epoch 445/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1655 - accuracy: 0.9995 - val_loss: 7.2358 - val_accuracy: 0.9950\n",
            "Epoch 446/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1622 - accuracy: 0.9995 - val_loss: 7.0782 - val_accuracy: 0.9950\n",
            "Epoch 447/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1641 - accuracy: 0.9998 - val_loss: 7.1032 - val_accuracy: 0.9950\n",
            "Epoch 448/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1639 - accuracy: 0.9996 - val_loss: 7.1786 - val_accuracy: 0.9950\n",
            "Epoch 449/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1603 - accuracy: 0.9995 - val_loss: 7.0758 - val_accuracy: 0.9950\n",
            "Epoch 450/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1623 - accuracy: 0.9995 - val_loss: 7.0956 - val_accuracy: 0.9950\n",
            "Epoch 451/500\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 0.1603 - accuracy: 0.9995 - val_loss: 7.0390 - val_accuracy: 0.9950\n",
            "Epoch 452/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1643 - accuracy: 0.9995 - val_loss: 7.1229 - val_accuracy: 0.9950\n",
            "Epoch 453/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1602 - accuracy: 0.9996 - val_loss: 7.1224 - val_accuracy: 0.9950\n",
            "Epoch 454/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1633 - accuracy: 0.9996 - val_loss: 7.0775 - val_accuracy: 0.9950\n",
            "Epoch 455/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1586 - accuracy: 0.9998 - val_loss: 7.1586 - val_accuracy: 0.9950\n",
            "Epoch 456/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1592 - accuracy: 0.9996 - val_loss: 7.0935 - val_accuracy: 0.9950\n",
            "Epoch 457/500\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.1620 - accuracy: 0.9998 - val_loss: 7.0716 - val_accuracy: 0.9950\n",
            "Epoch 458/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1622 - accuracy: 0.9996 - val_loss: 7.0881 - val_accuracy: 0.9950\n",
            "Epoch 459/500\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.1559 - accuracy: 0.9996 - val_loss: 7.0020 - val_accuracy: 0.9950\n",
            "Epoch 460/500\n",
            " 88/352 [======>.......................] - ETA: 2s - loss: 0.2466 - accuracy: 1.0000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "i = 1\n",
        "for index, value in enumerate(val_loss_values):\n",
        "    plt.plot(range(1, len(value[1])+1), value[1], label='Validation ' + str(i))\n",
        "    i+=1\n",
        "for index, value in enumerate(training_loss_values):\n",
        "    plt.plot(range(1, len(value[1])+1), value[1], label='Training ' + str(i),linestyle='--')\n",
        "    i+=1\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0nZz6v64qUDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, calculate the column means along axis 0 (columns)\n",
        "col_means = np.nanmean(y_test, axis=0)\n",
        "\n",
        "# Next, create the matrix 'p' using the calculated column means\n",
        "num_rows_d_test = y_test.shape[0]\n",
        "num_cols_d_train = y_train.shape[1]\n",
        "\n",
        "# Print RMSE\n",
        "print('RMSE : ')\n",
        "print(combined_loss)\n",
        "df['RMSE'] = combined_loss\n",
        "df.to_csv('/content/performance.csv',mode='a')"
      ],
      "metadata": {
        "id": "vA8P1bkO2yvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions = pd.DataFrame(combined_predictions)"
      ],
      "metadata": {
        "id": "O-4lCKuJDN5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 16 images in the DataFrame\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "fig.subplots_adjust(\n",
        "    left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "for i in range(16):\n",
        "  if model_type == 'Single hidden layer':\n",
        "    image = np.array(x_test.iloc[i,:])  # Convert the Series to a NumPy array\n",
        "    image = image.reshape((96, 96))  # Reshape the array to the desired image dimensions\n",
        "  elif model_type == 'Convolutions':\n",
        "    image = x_test[i]\n",
        "    image = image.reshape((96, 96))\n",
        "  ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
        "  predicted_keypoints = combined_predictions[i].reshape((15, 2))\n",
        "  plt.scatter(predicted_keypoints[:, 0], predicted_keypoints[:, 1], c='r', marker='o')\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "SMdqZBecLIOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO move below\n",
        "# from pandas.io.parsers.readers import read_csv\n",
        "# Extract data for output\n",
        "x_submission = load2d(fname = submission_filename)\n",
        "if pretraining == False:\n",
        "  submission_predictions_list = []\n",
        "\n",
        "  for setting in SPECIALIST_SETTINGS:\n",
        "      cols = setting['columns']\n",
        "      x_submission, _ = load2d(cols=cols,fname = submission_filename)\n",
        "\n",
        "      # Make predictions using this specialist on the cleaned test data\n",
        "      submission_predictions = specialists[cols].predict(x_submission)\n",
        "      submission_predictions_list.append(submission_predictions)\n",
        "\n",
        "  # Make predictions\n",
        "  predictions_submission = np.hstack(submission_predictions_list)\n",
        "else:\n",
        "  x_submission, _ = load2d(fname = submission_filename)\n",
        "  predictions_submission = net.predict(x_submission)\n",
        "# Remove predictions not requested in IdLookupTable.csv\n",
        "filename = '/content/IdLookupTable.csv'\n",
        "IdLookupTable = pd.read_csv(filename)\n",
        "# All keypoints names\n",
        "keypoints_names = IdLookupTable['FeatureName'].iloc[0:30]\n",
        "# Calculate the repeating sequence based on the number of rows in 'df'\n",
        "repeating_sequence = np.repeat(np.arange(1, 1783*30 // 30 + 1), 30)\n",
        "# Add the repeating sequence as a new column to the DataFrame\n",
        "keypoints_names_filter = pd.DataFrame({'ImageId': repeating_sequence})\n",
        "keypoints_names_filter['Indices'] = range(len(keypoints_names_filter))\n",
        "keypoints_names_filter['FeatureName'] = pd.concat([keypoints_names] * 1783, ignore_index=True)\n",
        "# Filter\n",
        "keypoints_names_filter = keypoints_names_filter.merge(IdLookupTable[['ImageId', 'FeatureName']], on=['ImageId', 'FeatureName'], how='inner')\n",
        "# Create a mask of size 1783x30 where True indicates the indices to keep\n",
        "nb_output_images = x_submission.shape[0]\n",
        "mask = np.isin(np.arange(nb_output_images*30), keypoints_names_filter['Indices'])\n",
        "# Reshape the mask to the same shape as 'np_array'\n",
        "mask = mask.reshape(predictions_submission.shape)\n",
        "# Use the mask to replace values in the NumPy array with NaN\n",
        "predictions_submission[~mask] = np.nan\n",
        "\n",
        "# Plot the first image in the DataFrame\n",
        "for i in range(16):\n",
        "  if model_type == 'Single hidden layer':\n",
        "    image = np.array(x_submission.iloc[-i,:])\n",
        "    image = image.reshape((96, 96))  # Reshape the array to the desired image dimensions\n",
        "  elif model_type == 'Convolutions':\n",
        "    image = x_submission[-i]\n",
        "    image = image.reshape((96, 96))\n",
        "  predicted_keypoints = predictions_submission[-i].reshape((15, 2))\n",
        "  plt.scatter(predicted_keypoints[:, 0], predicted_keypoints[:, 1], c='r', marker='o')\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "# Prepare for output file\n",
        "df_predictions = pd.DataFrame(predictions_submission)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array and reshape it\n",
        "reshaped_values = df_predictions.values.reshape(-1, 1)\n",
        "\n",
        "# Remove NaN values from the NumPy array\n",
        "reshaped_values = reshaped_values[~np.isnan(reshaped_values)]\n",
        "\n",
        "# Create a new DataFrame with the reshaped values\n",
        "reshaped_df = pd.DataFrame(reshaped_values, columns=['Value'])\n",
        "indices = pd.DataFrame(range(1,len(reshaped_df)+1))\n",
        "submission = pd.concat([indices, reshaped_df], axis=1)\n",
        "submission.rename(columns={0: 'RowId','Value': 'Location'}, inplace=True)\n",
        "\n",
        "# Write to csv file\n",
        "submission.to_csv('/content/model_submission.csv',index=False)\n"
      ],
      "metadata": {
        "id": "pwYDph1YMxwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}